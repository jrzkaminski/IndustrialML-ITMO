{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs, data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/train_preprocessed.csv')\n",
    "data_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/test.csv')\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/valid.csv')\n",
    "data_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict mean for each point\n",
    "\n",
    "For each centroid of the dataset we calculated mean value and rounded. We predicted this value for each timestamp inside of each centroid.\n",
    "\n",
    "Turns out that it is enough to accoplish the task:\n",
    "\n",
    "Validation dataset average error: 1.24\n",
    "\n",
    "Test dataset average error: 1.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_points = data_train['point'].unique()\n",
    "test_unique_points = data_test['point'].unique()\n",
    "valid_unique_points = data_val['point'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'point': data_train.groupby('point')['num_posts'].mean().index, 'num_posts_mean': data_train.groupby('point')['num_posts'].mean().values})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# let's find the mean values of num_posts for each point\n",
    "\n",
    "df_val_mean = pd.Series(df[df['point'] == el]['num_posts_mean'].values for el in data_val['point']).str[0]\n",
    "assert len(df_val_mean.unique()) == len(valid_unique_points)\n",
    "\n",
    "# and then calculate the error\n",
    "data_val['baseline_error'] = abs(data_val['sum'] - np.round(df_val_mean)) / np.round(df_val_mean)\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_avg_baseline_error = np.mean(data_val['baseline_error'])\n",
    "assert val_avg_baseline_error < np.mean(data_val['error']) # our baseline is better than your\n",
    "assert val_avg_baseline_error < 2.6 # and is better than needed\n",
    "val_avg_baseline_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_test_mean = pd.Series(df[df['point'] == el]['num_posts_mean'].values for el in data_test['point']).str[0]\n",
    "assert len(df_test_mean.unique()) == len(test_unique_points)\n",
    "\n",
    "data_test['baseline_error'] = abs(data_test['sum'] - np.round(df_test_mean)) / np.round(df_test_mean)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avg_baseline_error = np.mean(data_test['baseline_error'])\n",
    "assert test_avg_baseline_error < np.mean(data_test['error'])\n",
    "assert test_avg_baseline_error < 2.6\n",
    "test_avg_baseline_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beta solution\n",
    "Same concept, works, but slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_means_for_val = []\n",
    "# baseline_mape_val = []\n",
    "\n",
    "# for i in valid_unique_points:\n",
    "#     data_point = data_train[data_train['point'] == i]\n",
    "#     mean = data_point['num_posts'].mean()\n",
    "#     baseline_means_for_val.append(mean)\n",
    "\n",
    "# baseline_val = pd.DataFrame({'point': valid_unique_points, 'num_posts_mean': baseline_means_for_val})\n",
    "# baseline_val\n",
    "\n",
    "# for row in data_val.iterrows():\n",
    "#     baseline_mape_val.append(abs(row[1]['sum'] - baseline_val[baseline_val['point'] == row[1]['point']]['num_posts_mean']) / baseline_val[baseline_val['point'] == row[1]['point']]['num_posts_mean'])\n",
    "\n",
    "# baseline_mape_val = np.array(baseline_mape_val)\n",
    "\n",
    "# val_with_baseline = data_val.copy()\n",
    "# val_with_baseline['baseline_mean'] = baseline_mape_val\n",
    "# val_with_baseline['baseline_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_means_for_test = []\n",
    "# baseline_mape_test = []\n",
    "\n",
    "# for i in test_unique_points:\n",
    "#     data_point = data_train[data_train['point'] == i]\n",
    "#     mean = data_point['num_posts'].mean()\n",
    "#     baseline_means_for_test.append(mean)\n",
    "\n",
    "# baseline_test = pd.DataFrame({'point': test_unique_points, 'num_posts_mean': baseline_means_for_test})\n",
    "# baseline_test\n",
    "\n",
    "# for row in data_test.iterrows():\n",
    "#     baseline_mape_test.append(abs(row[1]['sum'] - baseline_test[baseline_test['point'] == row[1]['point']]['num_posts_mean']) / baseline_test[baseline_test['point'] == row[1]['point']]['num_posts_mean'])\n",
    "\n",
    "# baseline_mape_test = np.array(baseline_mape_test)\n",
    "\n",
    "# test_with_baseline = data_test.copy()\n",
    "# test_with_baseline['baseline_mean'] = baseline_mape_test\n",
    "# test_with_baseline['baseline_mean'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('indml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02902d8ec977eb7ac2114c5b569c3cebeb1ab04bf847c131eacd9d4311affd20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
