{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs, data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from joblib import dump, load\n",
    "from rich.progress import track\n",
    "\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "import holidays\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/train_preprocessed.csv')\n",
    "data_train.drop('Unnamed: 0', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/valid.csv')\n",
    "# drop row 0101000020E610000000000000000000000000000000000000\n",
    "data_val = data_val[data_val['point'] != '0101000020E610000000000000000000000000000000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_points = data_train['point'].unique()\n",
    "test_unique_points = data_test['point'].unique()\n",
    "valid_unique_points = data_val['point'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding datetime holidays, weekends, weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add datetime column to test and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['datetime'] = pd.to_datetime(data_test['hour'], unit='s')\n",
    "data_val['datetime'] = pd.to_datetime(data_val['hour'], unit='s')\n",
    "data_train['datetime'] = pd.to_datetime(data_train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>num_posts</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101000020E610000002A5EC7AB31D3E4097654065F8EA...</td>\n",
       "      <td>30.116020</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>2019-11-22 11:00:00</td>\n",
       "      <td>1574420400</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-22 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101000020E610000002A5EC7AB31D3E4097654065F8EA...</td>\n",
       "      <td>30.116020</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>2019-11-22 12:00:00</td>\n",
       "      <td>1574424000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-22 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101000020E610000002A5EC7AB31D3E4097654065F8EA...</td>\n",
       "      <td>30.116020</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>2019-11-23 13:00:00</td>\n",
       "      <td>1574514000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-23 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101000020E610000002A5EC7AB31D3E4097654065F8EA...</td>\n",
       "      <td>30.116020</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>2019-11-25 16:00:00</td>\n",
       "      <td>1574697600</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-25 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101000020E610000002A5EC7AB31D3E4097654065F8EA...</td>\n",
       "      <td>30.116020</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>2019-11-27 10:00:00</td>\n",
       "      <td>1574848800</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-27 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625651</th>\n",
       "      <td>0101000020E6100000FF9D4C0EC3853E4094782B2D0DF3...</td>\n",
       "      <td>30.522508</td>\n",
       "      <td>59.898840</td>\n",
       "      <td>2019-12-06 04:00:00</td>\n",
       "      <td>3151209600</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-06 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625652</th>\n",
       "      <td>0101000020E6100000FF9D4C0EC3853E4094782B2D0DF3...</td>\n",
       "      <td>30.522508</td>\n",
       "      <td>59.898840</td>\n",
       "      <td>2019-12-23 08:00:00</td>\n",
       "      <td>1577088000</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-23 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625653</th>\n",
       "      <td>0101000020E6100000FF9D4C0EC3853E40ABD94A1972EF...</td>\n",
       "      <td>30.522508</td>\n",
       "      <td>59.870670</td>\n",
       "      <td>2019-06-10 09:00:00</td>\n",
       "      <td>1560157200</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-10 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625654</th>\n",
       "      <td>0101000020E6100000FF9D4C0EC3853E40ABD94A1972EF...</td>\n",
       "      <td>30.522508</td>\n",
       "      <td>59.870670</td>\n",
       "      <td>2019-10-06 14:00:00</td>\n",
       "      <td>1570370400</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-06 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625655</th>\n",
       "      <td>0101000020E6100000FF9D4C0EC3853E40F2755E8979F2...</td>\n",
       "      <td>30.522508</td>\n",
       "      <td>59.894334</td>\n",
       "      <td>2019-08-16 10:00:00</td>\n",
       "      <td>1565949600</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-16 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3625656 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     point        lon  \\\n",
       "0        0101000020E610000002A5EC7AB31D3E4097654065F8EA...  30.116020   \n",
       "1        0101000020E610000002A5EC7AB31D3E4097654065F8EA...  30.116020   \n",
       "2        0101000020E610000002A5EC7AB31D3E4097654065F8EA...  30.116020   \n",
       "3        0101000020E610000002A5EC7AB31D3E4097654065F8EA...  30.116020   \n",
       "4        0101000020E610000002A5EC7AB31D3E4097654065F8EA...  30.116020   \n",
       "...                                                    ...        ...   \n",
       "3625651  0101000020E6100000FF9D4C0EC3853E4094782B2D0DF3...  30.522508   \n",
       "3625652  0101000020E6100000FF9D4C0EC3853E4094782B2D0DF3...  30.522508   \n",
       "3625653  0101000020E6100000FF9D4C0EC3853E40ABD94A1972EF...  30.522508   \n",
       "3625654  0101000020E6100000FF9D4C0EC3853E40ABD94A1972EF...  30.522508   \n",
       "3625655  0101000020E6100000FF9D4C0EC3853E40F2755E8979F2...  30.522508   \n",
       "\n",
       "               lat                 time   timestamp  num_posts  \\\n",
       "0        59.835705  2019-11-22 11:00:00  1574420400          1   \n",
       "1        59.835705  2019-11-22 12:00:00  1574424000          1   \n",
       "2        59.835705  2019-11-23 13:00:00  1574514000          1   \n",
       "3        59.835705  2019-11-25 16:00:00  1574697600          1   \n",
       "4        59.835705  2019-11-27 10:00:00  1574848800          1   \n",
       "...            ...                  ...         ...        ...   \n",
       "3625651  59.898840  2019-12-06 04:00:00  3151209600          2   \n",
       "3625652  59.898840  2019-12-23 08:00:00  1577088000          1   \n",
       "3625653  59.870670  2019-06-10 09:00:00  1560157200          1   \n",
       "3625654  59.870670  2019-10-06 14:00:00  1570370400          1   \n",
       "3625655  59.894334  2019-08-16 10:00:00  1565949600          1   \n",
       "\n",
       "                   datetime  \n",
       "0       2019-11-22 11:00:00  \n",
       "1       2019-11-22 12:00:00  \n",
       "2       2019-11-23 13:00:00  \n",
       "3       2019-11-25 16:00:00  \n",
       "4       2019-11-27 10:00:00  \n",
       "...                     ...  \n",
       "3625651 2019-12-06 04:00:00  \n",
       "3625652 2019-12-23 08:00:00  \n",
       "3625653 2019-06-10 09:00:00  \n",
       "3625654 2019-10-06 14:00:00  \n",
       "3625655 2019-08-16 10:00:00  \n",
       "\n",
       "[3625656 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weekday to test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"dayhour\"] = data_train[\"datetime\"].dt.hour\n",
    "data_train[\"weekday\"] = data_train[\"datetime\"].dt.weekday\n",
    "\n",
    "data_test[\"dayhour\"] = data_test[\"datetime\"].dt.hour\n",
    "data_test[\"weekday\"] = data_test[\"datetime\"].dt.weekday\n",
    "\n",
    "data_val[\"dayhour\"] = data_val[\"datetime\"].dt.hour\n",
    "data_val[\"weekday\"] = data_val[\"datetime\"].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_russia = holidays.country_holidays('RU', years = [2019, 2020])\n",
    "\n",
    "data_train['is_holiday'] = data_train['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_test['is_holiday'] = data_test['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_val['is_holiday'] = data_val['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    return abs(y_true - y_pred) / y_true\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def rfr_model_fit_predict(data_train: pd.DataFrame, data_test: pd.DataFrame, model):\n",
    "\n",
    "    data_test_rf_error = []\n",
    "    test_unique_points = data_test['point'].unique()\n",
    "\n",
    "    for point in track(test_unique_points, description='Fitting and predicting'):\n",
    "        data_train_point = data_train[data_train['point'] == point]\n",
    "        data_test_point = data_test[data_test['point'] == point]\n",
    "\n",
    "        X_train = data_train_point[['timestamp', 'dayhour', 'weekday', 'is_holiday']]\n",
    "        y_train = data_train_point['num_posts']\n",
    "        X_test = data_test_point[['hour', 'dayhour', 'weekday', 'is_holiday']]\n",
    "        y_test = data_test_point['sum']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        data_test_rf_error.append(custom_metric(y_test, y_pred))\n",
    "    \n",
    "    return data_test_rf_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data\n",
    "\n",
    "time = 203 s\n",
    "\n",
    "error = 0.8662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c99630c2ec48d6a674bf94e754b98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 14s, sys: 186 ms, total: 3min 14s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8662030853982366"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_test_rfr_error = rfr_model_fit_predict(data_train, data_test, RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "data_test_rfr_error = flatten(data_test_rfr_error)\n",
    "data_test['rfr_error'] = data_test_rfr_error\n",
    "data_test['rfr_error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data\n",
    "\n",
    "time = 195 s\n",
    "\n",
    "error = 0.86883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3215f970cd0e40579f817b65155604fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 15s, sys: 252 ms, total: 3min 16s\n",
      "Wall time: 3min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688384729816974"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_val_rfr_error = rfr_model_fit_predict(data_train, data_val, RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "data_val_rfr_error = flatten(data_val_rfr_error)\n",
    "data_val['rfr_error'] = data_val_rfr_error\n",
    "data_val['rfr_error'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('indml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02902d8ec977eb7ac2114c5b569c3cebeb1ab04bf847c131eacd9d4311affd20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
