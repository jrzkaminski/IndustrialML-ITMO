{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs, data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "from joblib import dump, load\n",
    "from rich.progress import track\n",
    "\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "import holidays\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/train_preprocessed.csv')\n",
    "data_train.drop('Unnamed: 0', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/valid.csv')\n",
    "# drop row 0101000020E610000000000000000000000000000000000000\n",
    "data_val = data_val[data_val['point'] != '0101000020E610000000000000000000000000000000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_points = data_train['point'].unique()\n",
    "test_unique_points = data_test['point'].unique()\n",
    "valid_unique_points = data_val['point'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding datetime holidays, weekends, weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add datetime column to test and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['datetime'] = pd.to_datetime(data_test['hour'], unit='s')\n",
    "data_val['datetime'] = pd.to_datetime(data_val['hour'], unit='s')\n",
    "data_train['datetime'] = pd.to_datetime(data_train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weekday to test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"dayhour\"] = data_train[\"datetime\"].dt.hour\n",
    "data_train[\"weekday\"] = data_train[\"datetime\"].dt.weekday\n",
    "\n",
    "data_test[\"dayhour\"] = data_test[\"datetime\"].dt.hour\n",
    "data_test[\"weekday\"] = data_test[\"datetime\"].dt.weekday\n",
    "\n",
    "data_val[\"dayhour\"] = data_val[\"datetime\"].dt.hour\n",
    "data_val[\"weekday\"] = data_val[\"datetime\"].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_russia = holidays.country_holidays('RU', years = [2019, 2020])\n",
    "\n",
    "data_train['is_holiday'] = data_train['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_test['is_holiday'] = data_test['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_val['is_holiday'] = data_val['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    return abs(y_true - y_pred) / y_true\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def rfr_model_fit_predict(data_train: pd.DataFrame, data_test: pd.DataFrame, model):\n",
    "\n",
    "    data_test_rf_error = []\n",
    "    test_unique_points = data_test['point'].unique()\n",
    "\n",
    "    for point in track(test_unique_points, description='Fitting and predicting'):\n",
    "        data_train_point = data_train[data_train['point'] == point]\n",
    "        data_test_point = data_test[data_test['point'] == point]\n",
    "\n",
    "        X_train = data_train_point[['timestamp', 'dayhour', 'weekday', 'is_holiday']]\n",
    "        y_train = data_train_point['num_posts']\n",
    "        X_test = data_test_point[['hour', 'dayhour', 'weekday', 'is_holiday']]\n",
    "        y_test = data_test_point['sum']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = np.round(model.predict(X_test))\n",
    "        data_test_rf_error.append(custom_metric(y_test, y_pred))\n",
    "    \n",
    "    return data_test_rf_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data\n",
    "\n",
    "time = 46 s\n",
    "\n",
    "error = 0.8662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_test_rfr_error = rfr_model_fit_predict(data_train, data_test, RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "data_test_rfr_error = flatten(data_test_rfr_error)\n",
    "data_test['rfr_error'] = data_test_rfr_error\n",
    "data_test['rfr_error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data\n",
    "\n",
    "time = 48 s\n",
    "\n",
    "error = 0.86883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_val_rfr_error = rfr_model_fit_predict(data_train, data_val, RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42))\n",
    "data_val_rfr_error = flatten(data_val_rfr_error)\n",
    "data_val['rfr_error'] = data_val_rfr_error\n",
    "data_val['rfr_error'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('indml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02902d8ec977eb7ac2114c5b569c3cebeb1ab04bf847c131eacd9d4311affd20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
