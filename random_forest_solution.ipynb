{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs, data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelling and Forecasting\n",
    "# ==============================================================================\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from datetime import date\n",
    "from joblib import dump, load\n",
    "\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "import holidays\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/train_preprocessed.csv')\n",
    "data_train.drop('Unnamed: 0', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('/home/jerzy/Documents/IndustrialML/data/valid.csv')\n",
    "# drop row 0101000020E610000000000000000000000000000000000000\n",
    "data_val = data_val[data_val['point'] != '0101000020E610000000000000000000000000000000000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique_points = data_train['point'].unique()\n",
    "test_unique_points = data_test['point'].unique()\n",
    "valid_unique_points = data_val['point'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into year, month, day, hour and adding holidays, weekends, weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add datetime column to test and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['datetime'] = pd.to_datetime(data_test['hour'], unit='s')\n",
    "data_val['datetime'] = pd.to_datetime(data_val['hour'], unit='s')\n",
    "data_train['datetime'] = pd.to_datetime(data_train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add yyyy, mm, dd, hh to test and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"year\"] = data_train[\"datetime\"].dt.year\n",
    "data_train[\"month\"] = data_train[\"datetime\"].dt.month\n",
    "data_train[\"day\"] = data_train[\"datetime\"].dt.day\n",
    "data_train[\"hour\"] = data_train[\"datetime\"].dt.hour\n",
    "data_train[\"weekday\"] = data_train[\"datetime\"].dt.weekday\n",
    "\n",
    "data_test[\"year\"] = data_test[\"datetime\"].dt.year\n",
    "data_test[\"month\"] = data_test[\"datetime\"].dt.month\n",
    "data_test[\"day\"] = data_test[\"datetime\"].dt.day\n",
    "data_test[\"hour\"] = data_test[\"datetime\"].dt.hour\n",
    "data_test[\"weekday\"] = data_test[\"datetime\"].dt.weekday\n",
    "\n",
    "data_val[\"year\"] = data_val[\"datetime\"].dt.year\n",
    "data_val[\"month\"] = data_val[\"datetime\"].dt.month\n",
    "data_val[\"day\"] = data_val[\"datetime\"].dt.day\n",
    "data_val[\"hour\"] = data_val[\"datetime\"].dt.hour\n",
    "data_val[\"weekday\"] = data_val[\"datetime\"].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_russia = holidays.country_holidays('RU', years = [2019, 2020])\n",
    "\n",
    "data_train['is_holiday'] = data_train['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_test['is_holiday'] = data_test['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)\n",
    "data_val['is_holiday'] = data_val['datetime'].apply(lambda x: 1 if x in holidays_russia else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest solution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
